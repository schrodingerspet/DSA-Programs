# Asymptotic Notations and Time Complexity

Understanding the performance of algorithms is crucial in computer science. Asymptotic notations provide a framework to analyze the efficiency of algorithms in terms of time and space.

## Asymptotic Notations

Asymptotic notations describe the behavior of functions as they approach a limit, often as input size increases. The main notations are:

- **Big O (O)**: Represents the **upper bound** of an algorithm's running time, indicating the worst-case scenario.

  \[
  O(f(n)) = \text{maximum time taken by the algorithm}
  \]

- **Theta (Θ)**: Represents the **exact bound**, indicating that the algorithm's running time grows at the same rate for both upper and lower bounds.

  \[
  Θ(f(n)) = \text{exact time taken by the algorithm}
  \]

- **Omega (Ω)**: Represents the **lower bound** of the algorithm's running time, indicating the best-case scenario.

  \[
  Ω(f(n)) = \text{minimum time taken by the algorithm}
  \]

---

## Time Complexity of Common Loops

Understanding the time complexity of loops is essential for analyzing algorithms. Below are the complexities of common loops:

- **Addition/Subtraction**: \( Θ(n) \)

    ```cpp
    for(int i = 0; i < n; i += c) {
        // operation
    }
    ```

- **Multiplication/Division**: \( Θ(\log n) \)

    ```cpp
    for(int i = 0; i < n; i *= c) {
        // operation
    }
    ```

- **Power**: \( Θ(\log \log n) \)

    ```cpp
    for(int i = 0; i < n; i = pow(i, c)) {
        // operation
    }
    ```

---

## Time Complexity of Complex Loops

### Combined Analysis of Loops

When analyzing the complexity of algorithms involving multiple loops, we consider the following scenarios:

1. **Subsequent Loops**

    ```cpp
    void fun(int n) {
        for(int i = 0; i < n; i++) {
            // operation
        }
        for(int i = 0; i < n; i *= 2) {
            // operation
        }
        for(int i = 0; i < 100; i++) {
            // operation
        }
    }
    ```

    **Complexity**: 
    \[
    Θ(n) + Θ(\log n) + Θ(1) = Θ(n)
    \]

2. **Nested Loops**

    ```cpp
    for(int i = 0; i < n; i++) {
        for(int j = 0; j < n; j *= 2) {
            // operation
        }
    }
    ```

    **Complexity**: 
    \[
    Θ(n) + Θ(\log n) = Θ(n \log n)
    \]

3. **Subsequent & Nested Loops**

    ```cpp
    for(int i = 0; i < n; i++) {
        for(int j = 0; j < n; j *= 2) {
            // operation
        }
    }

    for(int i = 0; i < n; i++) {
        for(int j = 0; j < n; j++) {
            // operation
        }
    }
    ```

    **Complexity**: 
    \[
    Θ(n \log n) + Θ(n^2) = Θ(n^2)
    \]

---

## Conclusion

Understanding asymptotic notations and time complexities allows developers to predict the efficiency of their algorithms. This knowledge helps in selecting the most suitable algorithm for a given problem.
